---
layout: post
title: "Arguments for the Neuroscience Approach to AI"
excerpt: "Why we should look to the brain to build AGI."
---

I'm often asked why I study the brain if I want to build AI. This is in contrast to the current state of AI that is dominated by machine learning and data science methods, and the previous paradigm of Good Old Fashioned Artificial Intelligence (GOFAI) that was dominated by rules and logic. In this post, I argue for the neuroscience approach to AI and why we should look to the brain for more than just inspiration.

I start with this question: What if AI's home field wasn't computer science? What if it lived in, say, the field of neuroscience or electrical engineering? The start of AI can be traced back to Alan Turing's 1950 paper "Computing Machinery and Intelligence" and to the 1956 Dartmouth summer workshop. These two events are the main reason why AI is in the domain of computer science, as it was computer scientists who wanted to imbue machines with intelligence. If history had taken a difference course, say that it was actually neuroscientists that wanted to recreate the brain, the field of AI might be a subfield of neuroscience. It's interesting that this didn't happen though but regardless, this question asks us to reflect on how much current AI research is biased towards a computer-science approach. However, this doesn't have to be the only way to the summit.

Another reason why I don't associate AI with computers is because this isn't the first time that the brain has been explained using a metaphor. Since the beginning of history, people have tried to explain the brain in terms of the most advanced technology of their era. For example, before the advent of electricity, people thought the brain was a mechanical device that worked on fluids and steam (hence the phrase "blowing off steam" to mean relieving stress/pressure). With the advent of electricity, the brain was thought to work like a telegraph. This is no different in our era as the computer is our most advanced technology and we use it to explain the brain and intelligence. However, it's inaccurate to compare the brain to computers as the metaphor falls apart in the details. It's more accurate to directly study the brain as it's own device, without any metaphors or expectations.

One of the strongest arguments for the neuroscience approach to AI is that the brain is the only existence proof of intelligence. So it makes sense that we would study the brain as has the properties that we want to replicate. However, a counter argument that people often bring up is the bird-and-airplane analogy. The analogy is that we didn't have to understand how birds fly in order to build airplanes. Likewise, they argue that we don't have to know how brains generate intelligence in order to build a machine that's intelligent. I disagree with the analogy because for man-made flight, we had a general principle that guided us to a different method of generating lift (without the need to flap wings): Bernoulli's law. We don't know of any such general principle for intelligence because intelligence isn't a physical property of the world (compared to pressure and speed). Intelligence is a dynamic property of living organisms that is constantly changing and evolving.

Perhaps what people mean by the analogy is that achieving a goal is irrelevant of the method. However, this doesn't hold up as when people were developing flight, we did look towards birds for inspiration. Similarly, discussions of AI always seem to make some reference to the brain. For example, in this [video](https://www.youtube.com/watch?v=g9V-MHxSCcs), the search for a solution comes back to how people solve the problem and how we can convert it into an algorithm/formalization. Another example is this [video](https://www.youtube.com/watch?v=oBklltKXtDE) where Andrej Karpathy states that we "don't shoot lasers out of our eyes in order to drive." So why do we only look to the brain for inspiration? Why not directly learn from and copy the brain?

I think two reasons why we avoid replicating the brain is because we don't know enough about the brain and because the brain is horribly complicated. I don't agree with the first reason as we know a lot about the brain as evidenced by the thousands of papers and tome-like textbooks that neuroscience has. Textbooks such as the *Principles of Neural Science* and *Cognitive Neuroscience: The Biology of the Mind* are massive and contain so much information about the brain; enough to build complicated model brains. As for the second reason, I agree that the brain is complicated but understanding what makes it complicated is why intelligence can emerge from it in the first place. To quote Ian Stewart, "If our brains were simple enough for us to understand them, we'd be so simple that we couldn't."

To wrap up, the quest for AI is a quest to build ourselves. The logical starting place is our brain and we should study the brain based on first principles. This means avoiding metaphors such as the brain as a telegraph or a computer. We know enough about the brain to start building brain-like devices, such as neuromorphic chips, that are faithful to how the brain works. By viewing and respecting the brain as its own unique device, we start appreciating just how remarkable, and yet ordinary, it is.

See [this post](https://brianpho.com/CR4-DL/other/lessons-from-the-brain/) for more technical details on how neuroscience can inform our journey of creating intelligent machine.
