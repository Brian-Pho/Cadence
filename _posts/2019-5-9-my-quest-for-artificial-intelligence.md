---
layout: post
title: "My quest for artificial intelligence"
---

This post logs my ongoing quest to create artificial general intelligence. I will continually update this post as I find more interesting ideas for creating AI.

---

#### Thoughts as of Dec 25, 2018

I'm keeping a "semi-journal" of my journey of becoming an AI researcher and (hopefully) creating AI.

I started this journey thinking that I'd go through my timeline of "tick-tock"ing computer science and neuroscience textbooks and posting notes from them here. After going through the first two textbooks, I came across the "Mastery" book that my sister left. After reading it, I was convinced that I wanted to become a master AI research on the likes of Einstein and Turing but for AI. It was also around this time that I knew I wasn't retaining and learning as much as I wanted from the textbooks and I searched for ways of learning to learn. I came across "Make It Stick" and I was sold on its conclusion of learning by distributed retrieval. After I read some excellent science fiction books (The three body problem series), I've returned back to my destiny, this time picking up "Peak".

With "Peak" completed, I think I'm done with this learning to learn and mastery/expertise path and I'm ready to tackle the actual AI research. There are a few other side skills that I want to learn (cooking, writing) but the meta-mastery is done. I'll always be reminded of Wade from "Death's End" in that we must keep advancing, stopping at nothing. The end goal is general artificial intelligence and nothing less.

The current plan is to devise a path to AI. I've brainstormed a few. One is to follow the evolution path and hope that creates AI but it's low chance to succeed with high time investment. Another is to follow the human path of starting at a child and working the ways up. It's higher chance to succeed but difficult.

---

#### Thoughts as of March 23, 2019

I've edited my last journal entry for clarity. Man was it bad. Anyways, I just completed the cognitive science textbook a week ago and I'm working on editing the notes to be more presentable. A few health problems have come up and if I die, I hope someone will take up this mantle of building AI with the neuroscience and cog sci approach. This is because I've realized something about problems in general; that they have weak points. And I believe that the weak point of AI is our brains because it's the only known object to exhibit intelligent behavior.

I'm still working out the details of how to create AI but one item I've made progress on is that we'll need some measure to see how close we are to AGI. "If you can't measure it, you can't improve it." Whether that be the complexity of the game it can play, how many jobs it can replace, or how close it is to passing the Turing test, we need some measure. I don't know what measure is relevant or best, but since we're aiming for AI, a measure of intelligence is needed (IQ isn't a very good measure).

---

#### Thoughts as of May 9, 2019

A lot of interesting things have happened since my last entry. I'll start with the biggest one.

I recently came across the idea of "neuromorphic computing" which is computation that based on the human brain. I first encountered it in the book "Artificial Intelligence: Perspectives from Leading Practitioners" where Dharmendra Modha talks about it. The main principles of a neuromorphic chip are that:

- non-Von Neumann architecture aka there's no separation between processing and memory.
- Event-based not clock-based like our current computers.
- Extremely power efficient as it doesn't waste energy updating clock cycles.
- Massively parallel.

I believe this is the missing piece in the quest for AI. I've always had some reservations and skepticism about using digital computers as the platform for AI and neuromorphic chips are the answer. This is the hardware piece of AI but we also need the software piece.

I'm currently taking a psychology course called "cognitive psychology" and I'm really enjoying it. As I've learnt more about the brain, the more I believe that AI will have to be a combination of specialized components like the brain. I haven't gotten to the book on this, but the brain seems to be a "kludge" where different parts are specialized for different functions. For example, we have a specific region for face recognition and if it's destroyed, people lose the ability to recognize faces (medically called prosopagnosia).

Another idea that's been marinating in my mind is that we need a theory of cognition/mind. The theory would explain how behavior arises from neural activity. An example would be that the release of the prolactin neurotransmitter explains why men can't continually orgasm. See [this](https://www.reddit.com/r/explainlikeimfive/comments/bl0if3/eli5_why_does_a_mans_penis_hurt_if_he_continues/) for more details.

Speaking of how neural activity translates to behavior, I think the mind-body problem in philosophy is ridiculous and a waste of time. The argument is based on the assumption that the mind and body is separate. However, this isn't empirically true as things that I do to my body affect my mind and vice versa. For example, I can take drugs and that has an effect on my mind. I can also use my mind to control my body. This suggests that there's a link between my mind and body hence they're not separate.
